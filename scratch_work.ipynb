{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code based on BreakfastPirate Forum post\n",
    "__author__ : SRK\n",
    "\"\"\"\n",
    "import csv\n",
    "import datetime\n",
    "from operator import sub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing, ensemble\n",
    "import pickle\n",
    "\n",
    "mapping_dict = {\n",
    "'ind_empleado'  : {-99:0, 'N':1, 'B':2, 'F':3, 'A':4, 'S':5},\n",
    "'sexo'          : {'V':0, 'H':1, -99:2},\n",
    "'ind_nuevo'     : {'0':0, '1':1, -99:2},\n",
    "'indrel'        : {'1':0, '99':1, -99:2},\n",
    "'indrel_1mes'   : {-99:0, '1.0':1, '1':1, '2.0':2, '2':2, '3.0':3, '3':3, '4.0':4, '4':4, 'P':5},\n",
    "'tiprel_1mes'   : {-99:0, 'I':1, 'A':2, 'P':3, 'R':4, 'N':5},\n",
    "'indresi'       : {-99:0, 'S':1, 'N':2},\n",
    "'indext'        : {-99:0, 'S':1, 'N':2},\n",
    "'conyuemp'      : {-99:0, 'S':1, 'N':2},\n",
    "'indfall'       : {-99:0, 'S':1, 'N':2},\n",
    "'tipodom'       : {-99:0, '1':1},\n",
    "'ind_actividad_cliente' : {'0':0, '1':1, -99:2},\n",
    "'segmento'      : {'02 - PARTICULARES':0, '03 - UNIVERSITARIO':1, '01 - TOP':2, -99:2},\n",
    "'pais_residencia' : {'LV': 102, 'BE': 12, 'BG': 50, 'BA': 61, 'BM': 117, 'BO': 62, 'JP': 82, 'JM': 116, 'BR': 17, 'BY': 64, 'BZ': 113, 'RU': 43, 'RS': 89, 'RO': 41, 'GW': 99, 'GT': 44, 'GR': 39, 'GQ': 73, 'GE': 78, 'GB': 9, 'GA': 45, 'GN': 98, 'GM': 110, 'GI': 96, 'GH': 88, 'OM': 100, 'HR': 67, 'HU': 106, 'HK': 34, 'HN': 22, 'AD': 35, 'PR': 40, 'PT': 26, 'PY': 51, 'PA': 60, 'PE': 20, 'PK': 84, 'PH': 91, 'PL': 30, 'EE': 52, 'EG': 74, 'ZA': 75, 'EC': 19, 'AL': 25, 'VN': 90, 'ET': 54, 'ZW': 114, 'ES': 0, 'MD': 68, 'UY': 77, 'MM': 94, 'ML': 104, 'US': 15, 'MT': 118, 'MR': 48, 'UA': 49, 'MX': 16, 'IL': 42, 'FR': 8, 'MA': 38, 'FI': 23, 'NI': 33, 'NL': 7, 'NO': 46, 'NG': 83, 'NZ': 93, 'CI': 57, 'CH': 3, 'CO': 21, 'CN': 28, 'CM': 55, 'CL': 4, 'CA': 2, 'CG': 101, 'CF': 109, 'CD': 112, 'CZ': 36, 'CR': 32, 'CU': 72, 'KE': 65, 'KH': 95, 'SV': 53, 'SK': 69, 'KR': 87, 'KW': 92, 'SN': 47, 'SL': 97, 'KZ': 111, 'SA': 56, 'SG': 66, 'SE': 24, 'DO': 11, 'DJ': 115, 'DK': 76, 'DE': 10, 'DZ': 80, 'MK': 105, -99: 1, 'LB': 81, 'TW': 29, 'TR': 70, 'TN': 85, 'LT': 103, 'LU': 59, 'TH': 79, 'TG': 86, 'LY': 108, 'AE': 37, 'VE': 14, 'IS': 107, 'IT': 18, 'AO': 71, 'AR': 13, 'AU': 63, 'AT': 6, 'IN': 31, 'IE': 5, 'QA': 58, 'MZ': 27},\n",
    "'canal_entrada' : {'013': 49, 'KHP': 160, 'KHQ': 157, 'KHR': 161, 'KHS': 162, 'KHK': 10, 'KHL': 0, 'KHM': 12, 'KHN': 21, 'KHO': 13, 'KHA': 22, 'KHC': 9, 'KHD': 2, 'KHE': 1, 'KHF': 19, '025': 159, 'KAC': 57, 'KAB': 28, 'KAA': 39, 'KAG': 26, 'KAF': 23, 'KAE': 30, 'KAD': 16, 'KAK': 51, 'KAJ': 41, 'KAI': 35, 'KAH': 31, 'KAO': 94, 'KAN': 110, 'KAM': 107, 'KAL': 74, 'KAS': 70, 'KAR': 32, 'KAQ': 37, 'KAP': 46, 'KAW': 76, 'KAV': 139, 'KAU': 142, 'KAT': 5, 'KAZ': 7, 'KAY': 54, 'KBJ': 133, 'KBH': 90, 'KBN': 122, 'KBO': 64, 'KBL': 88, 'KBM': 135, 'KBB': 131, 'KBF': 102, 'KBG': 17, 'KBD': 109, 'KBE': 119, 'KBZ': 67, 'KBX': 116, 'KBY': 111, 'KBR': 101, 'KBS': 118, 'KBP': 121, 'KBQ': 62, 'KBV': 100, 'KBW': 114, 'KBU': 55, 'KCE': 86, 'KCD': 85, 'KCG': 59, 'KCF': 105, 'KCA': 73, 'KCC': 29, 'KCB': 78, 'KCM': 82, 'KCL': 53, 'KCO': 104, 'KCN': 81, 'KCI': 65, 'KCH': 84, 'KCK': 52, 'KCJ': 156, 'KCU': 115, 'KCT': 112, 'KCV': 106, 'KCQ': 154, 'KCP': 129, 'KCS': 77, 'KCR': 153, 'KCX': 120, 'RED': 8, 'KDL': 158, 'KDM': 130, 'KDN': 151, 'KDO': 60, 'KDH': 14, 'KDI': 150, 'KDD': 113, 'KDE': 47, 'KDF': 127, 'KDG': 126, 'KDA': 63, 'KDB': 117, 'KDC': 75, 'KDX': 69, 'KDY': 61, 'KDZ': 99, 'KDT': 58, 'KDU': 79, 'KDV': 91, 'KDW': 132, 'KDP': 103, 'KDQ': 80, 'KDR': 56, 'KDS': 124, 'K00': 50, 'KEO': 96, 'KEN': 137, 'KEM': 155, 'KEL': 125, 'KEK': 145, 'KEJ': 95, 'KEI': 97, 'KEH': 15, 'KEG': 136, 'KEF': 128, 'KEE': 152, 'KED': 143, 'KEC': 66, 'KEB': 123, 'KEA': 89, 'KEZ': 108, 'KEY': 93, 'KEW': 98, 'KEV': 87, 'KEU': 72, 'KES': 68, 'KEQ': 138, -99: 6, 'KFV': 48, 'KFT': 92, 'KFU': 36, 'KFR': 144, 'KFS': 38, 'KFP': 40, 'KFF': 45, 'KFG': 27, 'KFD': 25, 'KFE': 148, 'KFB': 146, 'KFC': 4, 'KFA': 3, 'KFN': 42, 'KFL': 34, 'KFM': 141, 'KFJ': 33, 'KFK': 20, 'KFH': 140, 'KFI': 134, '007': 71, '004': 83, 'KGU': 149, 'KGW': 147, 'KGV': 43, 'KGY': 44, 'KGX': 24, 'KGC': 18, 'KGN': 11}\n",
    "}\n",
    "cat_cols = list(mapping_dict.keys())\n",
    "\n",
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "target_cols = target_cols[2:]\n",
    "\n",
    "def getTarget(row):\n",
    "\ttlist = []\n",
    "\tfor col in target_cols:\n",
    "\t\tif row[col].strip() in ['', 'NA']:\n",
    "\t\t\ttarget = 0\n",
    "\t\telse:\n",
    "\t\t\ttarget = int(float(row[col]))\n",
    "\t\ttlist.append(target)\n",
    "\treturn tlist\n",
    "\n",
    "def getIndex(row, col):\n",
    "\tval = row[col].strip()\n",
    "\tif val not in ['','NA']:\n",
    "\t\tind = mapping_dict[col][val]\n",
    "\telse:\n",
    "\t\tind = mapping_dict[col][-99]\n",
    "\treturn ind\n",
    "\n",
    "def getAge(row):\n",
    "\tmean_age = 40.\n",
    "\tmin_age = 20.\n",
    "\tmax_age = 90.\n",
    "\trange_age = max_age - min_age\n",
    "\tage = row['age'].strip()\n",
    "\tif age == 'NA' or age == '':\n",
    "\t\tage = mean_age\n",
    "\telse:\n",
    "\t\tage = float(age)\n",
    "\t\tif age < min_age:\n",
    "\t\t\tage = min_age\n",
    "\t\telif age > max_age:\n",
    "\t\t\tage = max_age\n",
    "\treturn round( (age - min_age) / range_age, 4)\n",
    "\n",
    "def getCustSeniority(row):\n",
    "\tmin_value = 0.\n",
    "\tmax_value = 256.\n",
    "\trange_value = max_value - min_value\n",
    "\tmissing_value = 0.\n",
    "\tcust_seniority = row['antiguedad'].strip()\n",
    "\tif cust_seniority == 'NA' or cust_seniority == '':\n",
    "\t\tcust_seniority = missing_value\n",
    "\telse:\n",
    "\t\tcust_seniority = float(cust_seniority)\n",
    "\t\tif cust_seniority < min_value:\n",
    "\t\t\tcust_seniority = min_value\n",
    "\t\telif cust_seniority > max_value:\n",
    "\t\t\tcust_seniority = max_value\n",
    "\treturn round((cust_seniority-min_value) / range_value, 4)\n",
    "\n",
    "def getRent(row):\n",
    "\tmin_value = 0.\n",
    "\tmax_value = 1500000.\n",
    "\trange_value = max_value - min_value\n",
    "\tmissing_value = 101850.\n",
    "\trent = row['renta'].strip()\n",
    "\tif rent == 'NA' or rent == '':\n",
    "\t\trent = missing_value\n",
    "\telse:\n",
    "\t\trent = float(rent)\n",
    "\t\tif rent < min_value:\n",
    "\t\t\trent = min_value\n",
    "\t\telif rent > max_value:\n",
    "\t\t\trent = max_value\n",
    "\treturn round((rent-min_value) / range_value, 6)\n",
    "\n",
    "def processData(in_file_name, cust_dict):\n",
    "\tx_vars_list = []\n",
    "\ty_vars_list = []\n",
    "\tfor row in csv.DictReader(in_file_name):\n",
    "\t\t# use only the four months as specified by breakfastpirate #\n",
    "\t\tif row['fecha_dato'] not in ['2015-05-28', '2015-06-28', '2016-05-28', '2016-06-28']:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tcust_id = int(row['ncodpers'])\n",
    "\t\tif row['fecha_dato'] in ['2015-05-28', '2016-05-28']:\t\n",
    "\t\t\ttarget_list = getTarget(row)\n",
    "\t\t\tcust_dict[cust_id] =  target_list[:]\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tx_vars = []\n",
    "\t\tfor col in cat_cols:\n",
    "\t\t\tx_vars.append( getIndex(row, col) )\n",
    "\t\tx_vars.append( getAge(row) )\n",
    "\t\tx_vars.append( getCustSeniority(row) )\n",
    "\t\tx_vars.append( getRent(row) )\n",
    "\n",
    "\t\tif row['fecha_dato'] == '2016-06-28':\n",
    "\t\t\tprev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "\t\t\tx_vars_list.append(x_vars + prev_target_list)\n",
    "\t\telif row['fecha_dato'] == '2015-06-28':\n",
    "\t\t\tprev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "\t\t\ttarget_list = getTarget(row)\n",
    "\t\t\tnew_products = [max(x1 - x2,0) for (x1, x2) in zip(target_list, prev_target_list)]\n",
    "\t\t\tif sum(new_products) > 0:\n",
    "\t\t\t\tfor ind, prod in enumerate(new_products):\n",
    "\t\t\t\t\tif prod>0:\n",
    "\t\t\t\t\t\tassert len(prev_target_list) == 22\n",
    "\t\t\t\t\t\tx_vars_list.append(x_vars+prev_target_list)\n",
    "\t\t\t\t\t\ty_vars_list.append(ind)\n",
    "\n",
    "\treturn x_vars_list, y_vars_list, cust_dict\n",
    "\n",
    "\n",
    "\t\t\t\n",
    "def runXGB(train_X, train_y, seed_val=0):\n",
    "\tparam = {}\n",
    "\tparam['objective'] = 'multi:softprob'\n",
    "\tparam['eta'] = 0.05\n",
    "\tparam['max_depth'] = 8\n",
    "\tparam['silent'] = 1\n",
    "\tparam['num_class'] = 22\n",
    "\tparam['eval_metric'] = \"mlogloss\"\n",
    "\tparam['min_child_weight'] = 1\n",
    "\tparam['subsample'] = 0.7\n",
    "\tparam['colsample_bytree'] = 0.7\n",
    "\tparam['seed'] = seed_val\n",
    "\tnum_rounds = 50\n",
    "\n",
    "\tplst = list(param.items())\n",
    "\txgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\tmodel = xgb.train(plst, xgtrain, num_rounds)\t\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData2(dictionary, cust_dict):\n",
    "    x_vars_list = []\n",
    "    y_vars_list = []\n",
    "    row = dictionary\n",
    "#     # use only the four months as specified by breakfastpirate #\n",
    "#     if row['fecha_dato'] not in ['2015-05-28', '2015-06-28', '2016-05-28', '2016-06-28']:\n",
    "#         continue\n",
    "\n",
    "    cust_id = int(row['ncodpers'])\n",
    "#     if row['fecha_dato'] in ['2015-05-28', '2016-05-28']:\n",
    "#         target_list = getTarget(row)\n",
    "#         cust_dict[cust_id] =  target_list[:]\n",
    "#         continue\n",
    "\n",
    "    x_vars = []\n",
    "    for col in cat_cols:\n",
    "        x_vars.append( getIndex(row, col) )\n",
    "    x_vars.append( getAge(row) )\n",
    "    x_vars.append( getCustSeniority(row) )\n",
    "    x_vars.append( getRent(row) )\n",
    "\n",
    "    if row['fecha_dato'] == '2016-06-28':\n",
    "        prev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "        x_vars_list.append(x_vars + prev_target_list)\n",
    "    elif row['fecha_dato'] == '2015-06-28':\n",
    "        prev_target_list = cust_dict.get(cust_id, [0]*22)\n",
    "        target_list = getTarget(row)\n",
    "        new_products = [max(x1 - x2,0) for (x1, x2) in zip(target_list, prev_target_list)]\n",
    "        if sum(new_products) > 0:\n",
    "            for ind, prod in enumerate(new_products):\n",
    "                if prod>0:\n",
    "                    assert len(prev_target_list) == 22\n",
    "                    x_vars_list.append(x_vars+prev_target_list)\n",
    "                    y_vars_list.append(ind)\n",
    "\n",
    "    return x_vars_list, y_vars_list, cust_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "data_path = \"santander-product-recommendation/\"\n",
    "train_file =  open(data_path + \"train_ver2.csv\")\n",
    "x_vars_list, y_vars_list, cust_dict = processData(train_file, {})\n",
    "train_X = np.array(x_vars_list)\n",
    "train_y = np.array(y_vars_list)\n",
    "print(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "(45679, 40) (45679,)\n",
      "0:02:00.431164\n",
      "(929615, 40)\n",
      "0:02:17.242107\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_y))\n",
    "del x_vars_list, y_vars_list\n",
    "train_file.close()\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(datetime.datetime.now()-start_time)\n",
    "test_file = open(data_path + \"test_ver2.csv\")\n",
    "x_vars_list, y_vars_list, cust_dict = processData(test_file, cust_dict)\n",
    "test_X = np.array(x_vars_list)\n",
    "del x_vars_list\n",
    "test_file.close()\n",
    "print(test_X.shape)\n",
    "print(datetime.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model..\n",
      "[23:04:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Predicting..\n",
      "0:02:43.383782\n",
      "Getting the top products..\n",
      "0:02:50.331095\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model..\")\n",
    "model = runXGB(train_X, train_y, seed_val=0)\n",
    "del train_X, train_y\n",
    "print(\"Predicting..\")\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "preds = model.predict(xgtest)\n",
    "del test_X, xgtest\n",
    "print(datetime.datetime.now()-start_time)\n",
    "\n",
    "print(\"Getting the top products..\")\n",
    "target_cols = np.array(target_cols)\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:,:7]\n",
    "test_id = np.array(pd.read_csv(data_path + \"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "final_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "out_df.to_csv('sub_xgb_new.csv', index=False)\n",
    "print(datetime.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('trained.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"santander-product-recommendation/\"\n",
    "train_file =  open(data_path + \"train_ver2.csv\")\n",
    "x_vars_list, y_vars_list, cust_dict = processData(train_file, {})\n",
    "del x_vars_list, y_vars_list\n",
    "train_file.close()\n",
    "\n",
    "cust_file = open(\"cust_dict.pkl\", \"wb\")\n",
    "pickle.dump(cust_dict, cust_file)\n",
    "cust_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedmodel = xgb.Booster()\n",
    "loadedmodel.load_model('trained.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x7f955fc1cca0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_file = open(\"cust_dict.pkl\", \"rb\")\n",
    "cust_dict = pickle.load(cust_file)\n",
    "dictionary = {'fecha_dato': '2016-06-28', 'ncodpers': '1170545', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'V', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'A', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': '15', 'nomprov': 'CORUÑA, A', 'ind_actividad_cliente': '1', 'renta': '         NA', 'segmento': '03 - UNIVERSITARIO'}\n",
    "dictionary['sexo'] = 'H'\n",
    "dictionary['pais_residencia'] = 'LV'\n",
    "dictionary['age'] = '23'\n",
    "dictionary['renta'] = '40000'\n",
    "dictionary['segmento'] = '01 - TOP'\n",
    "dictionary['ind_actividad_cliente'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars_list, y_vars_list, cust_dict = processData2(dictionary, cust_dict)\n",
    "test_X = np.array(x_vars_list)\n",
    "del x_vars_list\n",
    "test_file.close()\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "preds = loadedmodel.predict(xgtest)\n",
    "del test_X, xgtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the top products..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ind_recibo_ult1 ind_nomina_ult1 ind_nom_pens_ult1 ind_cno_fin_ult1 ind_ecue_fin_ult1 ind_dela_fin_ult1 ind_cco_fin_ult1']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Getting the top products..\")\n",
    "target_cols = np.array(target_cols)\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:,:7]\n",
    "final_preds = [\" \".join(list(target_cols[pred])) for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fecha_dato': '2016-06-28', 'ncodpers': '  15889', 'ind_empleado': 'F', 'pais_residencia': 'ES', 'sexo': 'V', 'age': ' 56', 'fecha_alta': '1995-01-16', 'ind_nuevo': '0', 'antiguedad': '    256', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'A', 'indresi': 'S', 'indext': 'N', 'conyuemp': 'N', 'canal_entrada': 'KAT', 'indfall': 'N', 'tipodom': '1', 'cod_prov': '28', 'nomprov': 'MADRID', 'ind_actividad_cliente': '1', 'renta': '  326124.90', 'segmento': '01 - TOP'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170544', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'H', 'age': ' 36', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'I', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KAT', 'indfall': 'N', 'tipodom': '1', 'cod_prov': ' 3', 'nomprov': 'ALICANTE', 'ind_actividad_cliente': '0', 'renta': '         NA', 'segmento': '02 - PARTICULARES'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170545', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'V', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'A', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': '15', 'nomprov': 'CORUÑA, A', 'ind_actividad_cliente': '1', 'renta': '         NA', 'segmento': '03 - UNIVERSITARIO'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170547', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'H', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'I', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': ' 8', 'nomprov': 'BARCELONA', 'ind_actividad_cliente': '0', 'renta': '  148402.98', 'segmento': '03 - UNIVERSITARIO'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170548', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'H', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'I', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': ' 7', 'nomprov': 'BALEARS, ILLES', 'ind_actividad_cliente': '0', 'renta': '  106885.80', 'segmento': '03 - UNIVERSITARIO'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170550', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'V', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'I', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': ' 8', 'nomprov': 'BARCELONA', 'ind_actividad_cliente': '0', 'renta': '         NA', 'segmento': '03 - UNIVERSITARIO'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170552', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'H', 'age': ' 51', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'A', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KFC', 'indfall': 'N', 'tipodom': '1', 'cod_prov': '35', 'nomprov': 'PALMAS, LAS', 'ind_actividad_cliente': '1', 'renta': '   96395.88', 'segmento': '02 - PARTICULARES'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170553', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'H', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'I', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': '45', 'nomprov': 'TOLEDO', 'ind_actividad_cliente': '0', 'renta': '         NA', 'segmento': '03 - UNIVERSITARIO'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170555', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'V', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'I', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': '28', 'nomprov': 'MADRID', 'ind_actividad_cliente': '0', 'renta': '         NA', 'segmento': '03 - UNIVERSITARIO'}\n",
      "{'fecha_dato': '2016-06-28', 'ncodpers': '1170557', 'ind_empleado': 'N', 'pais_residencia': 'ES', 'sexo': 'H', 'age': ' 22', 'fecha_alta': '2013-08-28', 'ind_nuevo': '0', 'antiguedad': '     34', 'indrel': ' 1', 'ult_fec_cli_1t': '', 'indrel_1mes': '1', 'tiprel_1mes': 'A', 'indresi': 'S', 'indext': 'N', 'conyuemp': '', 'canal_entrada': 'KHE', 'indfall': 'N', 'tipodom': '1', 'cod_prov': '15', 'nomprov': 'CORUÑA, A', 'ind_actividad_cliente': '1', 'renta': '   68322.72', 'segmento': '03 - UNIVERSITARIO'}\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "test_file = open(data_path + \"test_ver2.csv\")\n",
    "for row in csv.DictReader(test_file):\n",
    "    count = count + 1\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
